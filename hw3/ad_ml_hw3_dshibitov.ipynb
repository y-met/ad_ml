{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpora/WarAndPeace.txt', mode='r') as f:\n",
    "    wap_text = f.read()\n",
    "    \n",
    "with open('corpora/AnnaKarenina.txt', mode='r') as f:\n",
    "    ak_text = f.read()\n",
    "    \n",
    "all_text = ' '.join((wap_text, ak_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Реализуйте базовый частотный метод по Шерлоку Холмсу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' абвгдежзийклмнопрстуфхцчшщъыьэюя'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_letters = ''.join([' '] + [chr(i) for i in range(ord('а'), ord('а') + 32)])\n",
    "rus_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower().replace('ё', 'е')\n",
    "    text = ''.join(letter for letter in text if letter in rus_letters)\n",
    "    text = text.replace('   ', ' ')\n",
    "    text = text.replace('  ', ' ').replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_frequencies(text):\n",
    "    return {item[0]:item[1] for item in Counter(text).most_common()}\n",
    "\n",
    "\n",
    "def simple_encode(text):\n",
    "    text = clean_text(text)\n",
    "    letters_map = {letter: new_letter for letter, new_letter\n",
    "                   in zip(rus_letters, random.sample(rus_letters, len(rus_letters)))}\n",
    "    return ''.join(letters_map[letter] for letter in text)\n",
    "\n",
    "\n",
    "def simple_decode(all_text_letters, encoded_text):\n",
    "    encoded_text_letters = get_frequencies(encoded_text)\n",
    "    letters_map = {letter: new_letter for letter, new_letter\n",
    "                  in zip(encoded_text_letters.keys(), all_text_letters.keys())}\n",
    "    return ''.join(letters_map[letter] for letter in encoded_text)\n",
    "\n",
    "\n",
    "def accuracy(original_text, decoded_text):\n",
    "    numerator = 0\n",
    "    for i in range(len(original_text)):\n",
    "        if original_text[i] == decoded_text[i]:\n",
    "            numerator += 1\n",
    "    denominator = len(original_text) or 1\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в первый раз увидал нехлюдов катюшу тогда когда он на третьем курсе университета готовя свое сочинение о земельной собственности прожил лето у своих тетушек обыкновенно он с матерью и сестрой жил летом в материнском большом подмосковном имении но в этот год сестра его вышла замуж а мать уехала на воды за границу нехлюдову же надо было писать сочинение и он решил прожить лето у тетушек у них в их глуши было тихо не было развлечений тетушки же нежно любили своего племянника и наследника и он любил их любил их старомодность и простоту жизни'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Л. Н. Толстой. Воскресение (отрывок)\n",
    "\n",
    "test_text = '''В первый раз увидал Нехлюдов Катюшу тогда, когда он на третьем курсе университета, \n",
    "готовя свое сочинение о земельной собственности, прожил лето у своих тетушек. \n",
    "Обыкновенно он с матерью и сестрой жил летом в материнском большом подмосковном имении. \n",
    "Но в этот год сестра его вышла замуж, а мать уехала на воды за границу. \n",
    "Нехлюдову же надо было писать сочинение, и он решил прожить лето у тетушек. \n",
    "У них в их глуши было тихо, не было развлечений; тетушки же нежно любили своего племянника и наследника, \n",
    "и он любил их, любил их старомодность и простоту жизни.'''\n",
    "\n",
    "test_text = clean_text(test_text)\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бйэътбдуйтсчйяблюсиймъгищюабйпснщ яйнаоюсйпаоюсйамймсйнтънкъжйпятьъйямлбътьлнънсйоанабейьбаъйьашлмъмлъйайчъжъикмауйьафьнбъммаьнлйэтацлийиънайяйьбалгйнъня ъпйафдпмабъммайамйьйжснъткщйлйьъьнтауйцлийиънажйбйжснътлмьпажйфаик ажйэаюжаьпабмажйлжъмллймайбйвнанйоаюйьъьнтсйъоайбд исйчсжяцйсйжснкйяъгсисймсйбаюдйчсйотсмлзяймъгищюабяйцъймсюайфдиайэльснкйьашлмъмлъйлйамйтъ лийэтацлнкйиънайяйнъня ъпйяймлгйбйлгйоия лйфдиайнлгаймъйфдиайтсчбиъшъмлуйнъня плйцъймъцмайищфлилйьбаъоайэиъжеммлпсйлймсьиъюмлпсйлйамйищфлийлгйищфлийлгйьнстажаюмаьнкйлйэтаьнаняйцлчмл'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_text = simple_encode(test_text)\n",
    "encoded_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в зервчш ртй квамтс непсжмов утижьк иогмт уогмт он нт иреиыед укрле кнаверлаиеит гоиовю лвое лоханенае о йедесынош лояливеннолиа зробас сеио к лвоап иеикьеу оячуновенно он л дтиерыж а лелирош бас сеиод в дтиеранлуод яосыьод зомдолуовнод аденаа но в эиои гом лелирт его вчьст йтдкб т дтиы кептст нт вомч йт гртнацк непсжмовк бе нтмо ячсо залтиы лоханенае а он реьас зробаиы сеио к иеикьеу к нап в ап гскьа ячсо иапо не ячсо ртйвсехенаш иеикьуа бе небно сжяаса лвоего зседюннаут а нтлсемнаут а он сжяас ап сжяас ап литродомнолиы а зролиоик байна'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_letters = get_frequencies(clean_text(all_text))\n",
    "decoded_test_text = simple_decode(all_text_letters, encoded_test_text)\n",
    "decoded_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49171270718232046"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_text, decoded_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст лично для меня нечитаем, хотя доля правильно расшифрованных букв кажется не такой уж и маленькой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Реализуйте частотный метод биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_frequencies(text):\n",
    "    bigrams = [text[i:i + 2] for i in range(0, len(text) - 1, 2)]\n",
    "    return {item[0]:item[1] for item in Counter(bigrams).most_common()}\n",
    "\n",
    "\n",
    "def bigram_decode(all_text_bigrams, encoded_text):\n",
    "    encoded_text_bigrams = get_bigram_frequencies(encoded_test_text)\n",
    "    bigram_map = {bigram: new_bigram for bigram, new_bigram\n",
    "                  in itertools.zip_longest(\n",
    "                      encoded_text_bigrams.keys(), all_text_bigrams.keys(), fillvalue='  '\n",
    "                  )}\n",
    "    \n",
    "    result_text = ''.join([\n",
    "        bigram_map.get(encoded_text[i:i + 2], encoded_text[i:i + 2])\n",
    "        for i in range(0, len(encoded_text) - 1, 2)\n",
    "    ])\n",
    "    \n",
    "    if len(encoded_text) % 2 == 1:\n",
    "        result_text += ' '\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'по ек анкоровориог в пм  бтоилондео  ооти каоти  те и т  иодя атетнавеакдаы сту оспртосеазвиа  зчтов унил  чбыем ра жеь ин гй лоне сал вла овоа раенол итьесни дтитоовелниитдов стасег керь  сльал вла оя пов стобвская ю  лмоя чеавй каойсяно аго келорны осьлимеерь мих лиоримвал с нн экион мивэтвае и рамал и тваямуо  пм  бтоо тре ну н дренеейон мслам пгона к ткорузане салн та и но стсоылвыо гоомпоеносаредиеое нло же на дрекороисхоовшеол итьдиняна пев нсклепеа рача над ч ягоееное болатебеи  к ттаожзаноомскле вена у  сзнтей н ноне сь про ализ '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_bigrams = get_bigram_frequencies(clean_text(all_text))\n",
    "decoded_test_text = bigram_decode(all_text_bigrams, encoded_test_text)\n",
    "decoded_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06998158379373849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_text, decoded_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст нечитаем, при этом доля правильно расшифрованных букв сильно упала (примерно в 7 раз). Это вероятно имеет простое объяснение - нам нужен намного более длинный \"тестовый\" текст, чтобы набрать статистику встречаемости биграмм близкую, к статистике которую мы получаем на большом корпусе текстов (\"Война и мир\" + \"Анна Каренина\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MCMC-сэмплирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем предположить, что в тексте следующий символ зависит от предыдущего -> можем представить текст как марковскую цепь. На каждой итерации, будем менять символы в нашем словаре случайным образом. Будем рассчитывать правдоподобие для старой версии словаря и для новой. Если для новой версии правдоподобие больше - будем использовать новый словарь. Если нет - воспользуемся новым словарем с вероятностью exp(new_loglikelihood - old_loglikelihood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC:\n",
    "    def __init__(self, train, verbose=True):\n",
    "        self.compute_train_frequencies(train)\n",
    "        self.train_letters = [x[0] for x in get_frequencies(train)]\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def compute_train_frequencies(self, train):\n",
    "        frequencies = get_bigram_frequencies(train)\n",
    "        sum_all = np.sum(list(frequencies.values()))\n",
    "        frequencies = {k: (v / (sum_all + 1)) for k, v in frequencies.items()}\n",
    "        \n",
    "        self.none_frequency = np.min(list(frequencies.values()))\n",
    "        self.train_bigram_frequencies = frequencies\n",
    "        \n",
    "    def get_map_and_likelyhood(self, train_letters, test_letters, test):\n",
    "        letters_map = {letter: new_letter for letter, new_letter in zip(test_letters, train_letters)}\n",
    "        test_decoded = [letters_map[letter] for letter in test]\n",
    "        \n",
    "        log_likelyhood = 0\n",
    "        for i in range(len(test_decoded) - 2 + 1):\n",
    "            frequency = self.train_bigram_frequencies.get(''.join(test_decoded[i:i + 2]), self.none_frequency)\n",
    "            log_likelyhood += np.log(frequency)\n",
    "    \n",
    "        return letters_map, log_likelyhood\n",
    "    \n",
    "    def get_train_letters_transposition(self):\n",
    "        res = self.train_letters[:]\n",
    "        idx1, idx2 = np.random.choice(len(res), size=2, replace=False)\n",
    "        res[idx1], res[idx2] = res[idx2], res[idx1]\n",
    "        return res\n",
    "\n",
    "    def fit_predict(self, test, iterations):\n",
    "        test_letters = [x[0] for x in get_frequencies(test)]\n",
    "        letters_map, likelyhood = self.get_map_and_likelyhood(self.train_letters, \n",
    "                                                                        test_letters,\n",
    "                                                                        test)\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            temp_train_letters = self.get_train_letters_transposition()\n",
    "            temp_letters_map, temp_likelyhood = self.get_map_and_likelyhood(temp_train_letters,\n",
    "                                                                  test_letters,\n",
    "                                                                  test)\n",
    "            \n",
    "            if (temp_likelyhood > likelyhood \n",
    "                or np.exp(temp_likelyhood - likelyhood) > random.random()):\n",
    "                \n",
    "                self.train_letters = temp_train_letters\n",
    "                letters_map = temp_letters_map\n",
    "                likelyhood = temp_likelyhood\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f'New best likelyhood: {likelyhood}')\n",
    "        \n",
    "        return ''.join(letters_map[letter] for letter in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в первый раз увидал нехлюдов катюшу тогда когда он на третьем курсе университета готовя свое сожинение о земельной собственности прочил лето у своих тетушек обыкновенно он с матерью и сестрой чил летом в материнском большом подмосковном имении но в этот год сестра его вышла замуч а мать уехала на воды за границу нехлюдову че надо было писать сожинение и он решил прочить лето у тетушек у них в их глуши было тихо не было развлежений тетушки че нечно любили своего племянника и наследника и он любил их любил их старомодность и простоту чизни'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = MCMC(clean_text(all_text), verbose=False)\n",
    "test_decoded = mcmc.fit_predict(encoded_test_text, 9000)\n",
    "test_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797421731123389"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_text, test_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст стал читаем (практически идеально), доля правильно расшифрованных букв также очень сильно выросла. Кажется, все ок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Расшифруйте сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_1 = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите норчальный или подти норчальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите чаксичальный балл за послемнее детвертое замание курса хотя конедно я нидего не обещаш'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = MCMC(clean_text(all_text), verbose=False)\n",
    "symbols_decoded_1 = mcmc.fit_predict(symbols_1, 90000)\n",
    "symbols_decoded_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_2 = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожбения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса хотя конечно я ничего не ожебаф'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = MCMC(clean_text(all_text), verbose=False)\n",
    "symbols_decoded_2 = mcmc.fit_predict(symbols_2, 90000)\n",
    "symbols_decoded_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст в целом читаем. Спасибо за интересное и наглядное упражнение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
